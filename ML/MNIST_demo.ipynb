{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying digits with convolutional neural networks\n",
    "\n",
    "This notebook contains the solution to the MNIST activity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "\n",
    "Both Keras and TF-Learn contain the MNIST dataset that can be quickly loaded with some helper functions. This solution will use TF-Learn but the Keras solution will be commented out. The two libraries are very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 28, 28) y_train.shape: (60000,)\n",
      "X_train[0][0]: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_train[0]: 5\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load both the training and test data from Keras\n",
    "# The X variables are the features and Y the ground truth categories \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# we see that the training data has 60000 instances with 28x28 pixels\n",
    "# and 10 categories, one for each digit\n",
    "print(\"X_train.shape:\", X_train.shape,\"y_train.shape:\", y_train.shape)\n",
    "\n",
    "# X_train[0] is the first image and  X_train[0][0] is the first row of pixels\n",
    "print(\"X_train[0][0]:\", X_train[0][0])\n",
    "# y_train[0] is the ground truth for the digit that X_train[0] represents\n",
    "print(\"y_train[0]:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape: (60000, 10)\n",
      "y_train[0]: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# y_train is now a one-hot encoding of the ground truth\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "# first value an arry of ten binary digets with one corresponding to 5 the only 1\n",
    "print(\"y_train[0]:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the ConvNet \n",
    "\n",
    "Create a small convolutional that will run on a CPU, so only use about 6 and 8 kernels in each convolutional layer. For the fully connected layer, just use a 32 to 64 units as well. We won't get state of the art performance but we don't want to wait all day for it to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 6)         60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 8)         440       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                6432      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 7,262\n",
      "Trainable params: 7,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------------\n",
    "# Keras\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten, merge\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "#keras.callbacks.TensorBoard(log_dir='/tmp/tflearn_logs')\n",
    "\n",
    "\n",
    "# 28x28 matrix of bits\n",
    "cnn_input = Input(shape=(28, 28, 1), name='Input')\n",
    "\n",
    "net = Conv2D(6, (3,3), activation='relu')(cnn_input)\n",
    "net = MaxPooling2D(pool_size=(2,2))(net)\n",
    "\n",
    "net = Conv2D(8, (3,3), activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=(2,2))(net)\n",
    "\n",
    "# keras uses a flatten layer when going from convolutional layers to normal\n",
    "net = Flatten()(net)\n",
    "\n",
    "net = Dense(32, activation='relu')(net)\n",
    "net = Dropout(rate=0.5)(net)\n",
    "\n",
    "out = Dense(10, activation='softmax')(net)\n",
    "model = Model(inputs=cnn_input, outputs=out)\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network\n",
    "\n",
    "Train the network and use the test data as the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 2.7511 - acc: 0.3000\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 1.4389 - acc: 0.4734\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 19s 321us/step - loss: 1.0725 - acc: 0.6245\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 19s 322us/step - loss: 0.8350 - acc: 0.7153\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 19s 318us/step - loss: 0.7213 - acc: 0.7589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121195518>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Keras Train\n",
    "model.fit(np.expand_dims(X_train, -1), y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 83us/step\n",
      "\n",
      "Loss: 0.21377041118144988 Accuracy: 0.9611\n"
     ]
    }
   ],
   "source": [
    "performance = model.evaluate(np.expand_dims(X_test, -1), y_test)\n",
    "\n",
    "print()\n",
    "print('Loss:', performance[0], 'Accuracy:', performance[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
